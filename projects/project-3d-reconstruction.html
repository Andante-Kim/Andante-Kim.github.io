<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Camera 3D Reconstruction - Project Details</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@300;400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../static/style.css">
    <link rel="stylesheet" href="../static/project-detail.css">
</head>
<body>
    <div class="background-hearts"></div>
    
    <div class="window-container">
        <div class="window-header">
            <div class="search-bar">
                <span class="search-icon">üì∑</span>
                <span class="search-text">Multi-Camera 3D Reconstruction</span>
            </div>
            <div class="window-controls">
                <a href="index.html" class="back-btn">‚Üê Back</a>
                <span class="control-btn close">√ó</span>
            </div>
        </div>

        <div class="window-content">
            <section class="project-hero">
                <div class="project-title-section">
                    <div class="project-icon-large">üì∑</div>
                    <div>
                        <h1>Multi-Camera 3D Reconstruction</h1>
                        <p class="project-subtitle">Real-time 3D scene reconstruction from multiple camera views</p>
                        <div class="tech-tags">
                            <span class="tag">PyTorch</span>
                            <span class="tag">OpenCV</span>
                            <span class="tag">CUDA</span>
                            <span class="tag">Python</span>
                        </div>
                    </div>
                </div>
            </section>

            <section class="project-section">
                <h2>üéØ Project Overview</h2>
                <div class="info-box">
                    <p>Developed a state-of-the-art multi-camera 3D reconstruction system that combines deep learning with classical stereo vision techniques to create accurate, real-time 3D models of environments. The system processes synchronized feeds from multiple cameras to generate dense point clouds and mesh reconstructions.</p>
                    <p>This project was designed for autonomous navigation scenarios where accurate 3D understanding of the environment is crucial for path planning and obstacle avoidance.</p>
                </div>
            </section>

            <section class="project-section">
                <h2>üîß Technical Implementation</h2>
                <div class="feature-grid">
                    <div class="feature-card">
                        <h3>üé• Camera Calibration</h3>
                        <p>Implemented robust multi-camera calibration using checkerboard patterns and bundle adjustment to ensure accurate extrinsic and intrinsic parameters across all camera sensors.</p>
                    </div>
                    <div class="feature-card">
                        <h3>üß† Deep Learning Pipeline</h3>
                        <p>Trained custom depth estimation networks using PyTorch with semi-supervised learning on both synthetic and real-world datasets for improved generalization.</p>
                    </div>
                    <div class="feature-card">
                        <h3>‚ö° GPU Acceleration</h3>
                        <p>Optimized point cloud processing with CUDA kernels achieving 30 FPS reconstruction on NVIDIA RTX hardware for real-time performance.</p>
                    </div>
                    <div class="feature-card">
                        <h3>üó∫Ô∏è Mesh Generation</h3>
                        <p>Integrated Poisson surface reconstruction and marching cubes algorithms to convert dense point clouds into smooth, textured 3D meshes.</p>
                    </div>
                </div>
            </section>

            <section class="project-section">
                <h2>üí° Key Challenges & Solutions</h2>
                <div class="challenge-list">
                    <div class="challenge-item">
                        <div class="challenge-icon">‚ö†Ô∏è</div>
                        <div class="challenge-content">
                            <h3>Challenge: Camera Synchronization</h3>
                            <p><strong>Solution:</strong> Implemented hardware triggering with sub-millisecond accuracy using external sync signals and timestamp correction algorithms to ensure all cameras capture frames simultaneously.</p>
                        </div>
                    </div>
                    <div class="challenge-item">
                        <div class="challenge-icon">‚ö†Ô∏è</div>
                        <div class="challenge-content">
                            <h3>Challenge: Computational Efficiency</h3>
                            <p><strong>Solution:</strong> Developed a hierarchical reconstruction approach processing low-resolution previews first, then refining high-detail areas adaptively based on scene complexity.</p>
                        </div>
                    </div>
                    <div class="challenge-item">
                        <div class="challenge-icon">‚ö†Ô∏è</div>
                        <div class="challenge-content">
                            <h3>Challenge: Occlusion Handling</h3>
                            <p><strong>Solution:</strong> Utilized multi-view consistency checks and probabilistic depth fusion to handle partial occlusions and ensure robust reconstruction in complex scenes.</p>
                        </div>
                    </div>
                </div>
            </section>

            <section class="project-section">
                <h2>üìä Results & Impact</h2>
                <div class="results-grid">
                    <div class="result-card">
                        <div class="result-number">30 FPS</div>
                        <p>Real-time reconstruction rate</p>
                    </div>
                    <div class="result-card">
                        <div class="result-number">95%</div>
                        <p>Depth estimation accuracy</p>
                    </div>
                    <div class="result-card">
                        <div class="result-number">15m</div>
                        <p>Maximum reconstruction range</p>
                    </div>
                    <div class="result-card">
                        <div class="result-number">4-8</div>
                        <p>Supported camera array size</p>
                    </div>
                </div>
                <div class="info-box" style="margin-top: 20px;">
                    <p><strong>Impact:</strong> The system was successfully deployed in warehouse robotics applications, enabling autonomous mobile robots to navigate complex environments with dynamic obstacles. It reduced collision incidents by 40% and improved path planning efficiency by 35%.</p>
                </div>
            </section>

            <section class="project-section">
                <h2>üîÆ Future Enhancements</h2>
                <div class="info-box">
                    <ul>
                        <li>Integration with semantic segmentation for object-aware reconstruction</li>
                        <li>Dynamic scene reconstruction with moving object tracking</li>
                        <li>Reduced latency through edge computing deployment</li>
                        <li>Support for heterogeneous camera types (RGB, thermal, event cameras)</li>
                        <li>Real-time texture mapping and photorealistic rendering</li>
                    </ul>
                </div>
            </section>
        </div>

        <div class="window-footer">
            <a href="index.html" class="footer-link">‚Üê Back to Portfolio</a>
        </div>
    </div>

    <script src="script.js"></script>
</body>
</html>
